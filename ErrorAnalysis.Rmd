---
output: html_document
---
NOSAMS Facility Error Analysis
========================================================

`r as.character(format(Sys.Date(), format="%B %d, %Y"))`



```{r Setup, echo=FALSE, warning=FALSE, message=FALSE}

#Load Libraries
library(dplyr)
library(ggplot2)
library(knitr)
library(shiny)
library(amstools)

#set parameters
from <- '2014-09-01'
to <- 'present' #present or date
sys <- 'both' #cfams, usams, ams1 or both
size <- c(40,300)

#Set digits for output
options(digits=4)

# Get fresh secondary data
#out <- getQCData(from, to, sys)

#Load QC data from file
load("qcData.rda")

```

# Underreported error in primary standards

Simple case first. Using only primary standards. This has the advantages of a large sample set that's the same on both systems, and does not require any normalization of means or variances.

First, lets filter out all primary standards from `r from` to `r to`, eliminating all samples less than `r size[1]`umol.

```{r}
#Filter data
stds <- filter(out, primary == TRUE, #use only normalizing ox-I
               grepl("OX-I", name), !grepl("OX-II", name),
               as.Date(tp_date_pressed) >= as.Date(from),
                as.Date(tp_date_pressed) <= ifelse(to != 'present', to, Sys.Date()),
                gf_co2_qty > size[1], gf_co2_qty < size[2], #Select size range
                lab == "OSG", #Use only samples from the SPL
                is.na(q_flag) #Check for q_flag
		)

# Calculate per-sample intrinsic error
fm.sd <- sd(stds$f_modern)
stds$interr <- sapply(stds$rep_err, intrErr, popErr = fm.sd)

#Make summary table
stds %>%
	group_by(system) %>%
	summarize(
                fm = mean(f_modern),
                fm.sd = sd(f_modern),
                int.m = mean(interr, na.rm = TRUE),
                int.sd = sd(interr, na.rm = TRUE),
                rep_err = mean(rep_err),
                N = length(f_modern))


#knitr::kable(prisum, digits = 4, caption = "Summary data for all primaries")
```

## Filtering

Removing outliers makes a difference for the difference between reported error and sd.

### IAEA/FIRI method

The radiocarbon intercomparison project defines outliers by two metrics. The first eliminates samples too far from the median of the population, and the second removes points with poor measurement precision. These are defined as follows:

Filter out the outliers using the two outlier tests from Rozanski et al. (1992).

* Omit values $< H_L-3(H_U-H_L)$ or $> H_L+3(H_U-H_L)$ where $H_L$ and $H_U$
are the lower and upper quartiles, respectively.

* $|(Fm-m)/\sigma|<2$ where $Fm$ is the measurement, $m$ is the median after outliers are removed as above, and $\sigma$ is the reported error of the measurement.

```{r outliers}
# 1st outlier test
q <- quantile(stds$f_modern, probs = c(.25, .75), names = FALSE)
oh <- q[2]+3*(q[2]-q[1])
ol <- q[1]-3*(q[2]-q[1])

stds.f <- stds %>% filter( f_modern < oh,
                     f_modern > ol)
                     
# second outlier test
m <- median(stds.f$f_modern)
stds.f <- stds.f %>% filter(abs((f_modern - m)/rep_err) < 2)

# Calculate per-sample intrinsic error
fm.sd <- sd(stds.f$f_modern)
stds.f$interr <- sapply(stds.f$rep_err, intrErr, popErr = fm.sd)

stds.f %>%
	group_by(system) %>%
	summarize(
                fm = mean(f_modern),
                fm.sd = sd(f_modern),
                rep_err = mean(rep_err),
                int.m = mean(interr, na.rm = TRUE),
                int.sd = sd(interr, na.rm = TRUE),
                N = length(f_modern))

```
## Weighted mean and deviation

The IAEA/FIRI method then goes on to define methods for determination of weighted mean and SD.

## Filtering by sigma and error

Alternatively, the effect of filtering can be seen interactively using the widgets below.

```{r echo = FALSE}
sliderInput("sigma", "Max Sigma",
            0, 12, value = 10)
sliderInput("fme", "Max reported error",
            0, 0.05, value = 0.05)


stds.r <- reactive({
    # Due to dplyr issue #318, we need temp variables for input values
    sig <- input$sigma
    fme <- input$fme

    # Apply filters
    stds %>%
      filter(
        sigma < sig, sigma > -sig, #Select reasonable sigmas
        rep_err < fme
        )
})

renderTable({
  #Make summary table
  stds.r() %>%
    group_by(system) %>%
    summarize(
      nFm = mean(normFm),
      nFm.s = sd(normFm),
      sig = mean(sigma),
      ferr = mean(frep_err),
      N = n()
      )
  
}, digits = 4)

# Histograms

renderPlot({
ggplot(stds.r(), aes(sigma)) + 
  geom_histogram(bins = input$bins) + 
  facet_grid(system ~ .) + 
  ggtitle(paste("Sigma Histogram"))
})
sliderInput("bins", "number of histogram bins",
            1, 100, value = 30)
```

# Underestimation of error in secondary standards

Secondaries need to be weighted using their precision and normalized to the mean of the population. Do we need to normalize variance too?


Analysis of performance of all secondary standards for `r sys` from `r from` to `r to`. Sample size is from `r size[1]` to `r size[2]`umol, outliers have been removed by sigma (-10 to 10) and normalized Fm (-0.02 to 0.02), and only secondaries Fm > .1 used.



Normalized fm difference is defined as:

$\frac{Fm_{m}-Fm_{c}}{Fm_{c}}$

where $Fm_{m}$ is measured Fm and $Fm_{c}$ is consensus Fm.

## By Secondary and System

Calculations of intrinsic error are added in below. "Intrerr" is the intrinsic error for data without normalizing Fm, and fintrerr is the intrinsic error calclulated for normalized data. Intrinsic error is calculated as follows:

$\sigma_{int}=\sqrt{\sigma_{tot}^2-\sigma_{tgt}^2}$

where $\sigma_{int}$ is the "intrinsic" error, $\sigma_{tot}$ is the total error and $\sigma_{tgt}$ is the "reported" or per-target error. $\sigma_{tot}$ is assumed to be the standard deviation of measurements of a secondary, and the mean of reported errors for a secondary is used for $\sigma_{tgt}$.

All values of NaN are cases where $\sigma_{tot}<\sigma_{tgt}$, ie. the mean reported error is greater than the actual population error.


# Calculating intrinsic error on a per sample basis

## Using all secondary data

Intrinsic errors are calculated per-sample using the per-sample reported error, $\sigma_{tgt}$ and the standard deviation of all measurements of that secondary sorted by system.

```{r psintrinsic, echo=FALSE, message=FALSE, warning=FALSE}

#secsumu <- filter(secsum, system == "USAMS")
#secu <- filter(out.s, system == "USAMS")
#secu <- left_join(secu, secsumu, by="name")
#secu <- mutate(secu, intrinsic = intrErr(fm.s, merr))
#secu <- mutate(secu, fintrinsic = intrErr(nFm.s, fmaxerr))
#
#secsumc <- filter(secsum, system == "CFAMS")
#secc <- filter(out.s, system == "CFAMS")
#secc <- left_join(secc, secsumc, by="name")
#secc <- mutate(secc, intrinsic = intrErr(fm.s, merr))
#secc <- mutate(secc, fintrinsic = intrErr(nFm.s, fmaxerr))
#
#sec <- bind_rows(secu,secc)
#
#intsum <- ddply(sec, .(name, system.y), summarize,
#                fm.e = mean(fm_consensus),
#                fm = mean(f_modern),
#                fm.s = sd(f_modern),
#                err = mean(merr),
#                int = mean(intrinsic),
#                nFm = mean(normFm),
#                nFm.s = sd(normFm),
#                ferr = mean(fmaxerr),
#                fintrerr = mean(fintrinsic),
#               N = length(f_modern))
#
#knitr::kable(intsum, digits = 4, caption = "Summary data for secondaries")
```

## By System

Same as above, only the grand total by system. Only cases where $\sigma_{tot}<\sigma_{tgt}$, ie. the mean reported error is greater than the actual population error are used. This biases the intrinsic error heavily towards data from higher Fm samples. THis also reduces N for CFAMS due to higher reported errors on low Fm samples.

```{r, echo=FALSE, message=FALSE}
#
##Make summary table
#sec <- select(sec, system.y, normFm, fmaxerr, fintrinsic, f_modern)
#sec <- sec[complete.cases(sec),]
#syssum <- ddply(sec, .(system.y), summarize,
#                nFm = mean(normFm),
#                nFm.s = sd(normFm),
#                ferr = mean(fmaxerr),
#                fintrerr = mean(fintrinsic),
#                N = length(f_modern))
#
#knitr::kable(syssum, digits = 4, caption = "Summary data for secondaries")
#
```
